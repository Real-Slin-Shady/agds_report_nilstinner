---
title: "Report Machine Learning 2"
author: "Nils Tinner"
date: "`r Sys.Date()`"
output: html_document
---
# Setup and Data cleaning

```{r, message = F}

# Package names
packages <- c("lubridate","tidyverse","visdat","yardstick","purrr","reshape2","rsample","recipes","caret","cowplot","stringr")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}else{
  print("All packages sucessfully installed")
}


invisible(lapply(packages, library, character.only = TRUE))

clean_up <- function(df){#Define function for cleanup since duplicated code is smelly
  df <- df |>
  # select only the variables we are interested in
  dplyr::select(TIMESTAMP,
                GPP_NT_VUT_REF,    
                SW_IN_F,  
                VPD_F,   
                TA_F,
                ends_with("_QC")# weird useless variable
                ) |>

  # convert to a nice date object
  dplyr::mutate(TIMESTAMP = ymd(TIMESTAMP)) |>

  # set all -9999 to NA
  dplyr::mutate(across(where(is.numeric), ~na_if(., -9999))) |> 
  
  # retain only data based on >=80% good-quality measurements
  # overwrite bad data with NA (not dropping rows)
  dplyr::mutate(GPP_NT_VUT_REF = ifelse(NEE_VUT_REF_QC < 0.8, NA, GPP_NT_VUT_REF),
                TA_F           = ifelse(TA_F_QC        < 0.8, NA, TA_F),
                SW_IN_F        = ifelse(SW_IN_F_QC     < 0.8, NA, SW_IN_F),
                VPD_F          = ifelse(VPD_F_QC       < 0.8, NA, VPD_F))|> 

  # drop QC variables (no longer needed)
  dplyr::select(-ends_with("_QC")) 
    return(df)
} 
daily_fluxes_dav <- read_csv("../data/FLX_CH-Dav_FLUXNET2015_FULLSET_DD_1997-2014_1-3.csv") |>
clean_up()

daily_fluxes_lae <- read_csv("../data/FLX_CH-Lae_FLUXNET2015_FULLSET_DD_2004-2014_1-4.csv") |>
clean_up()

miss_dav <- vis_miss(
  daily_fluxes_dav,
  cluster = FALSE, 
  warn_large_data = FALSE
  )

miss_lae <- vis_miss(
  daily_fluxes_lae,
  cluster = FALSE, 
  warn_large_data = FALSE
  )

cowplot::plot_grid(miss_lae, miss_dav,
                   labels = c("Laegern",
                              "Davos"))

set.seed(1982)
rm(miss_lae,miss_dav)
```

The loading process is almost the same as in re_ml_1 except that Longwave radiation is not kept since there are just too many missing data values that impact our models in davos. Now we have mostly non missing data for the evaluation.

```{r}
set.seed(1982)  # for reproducibility
split <- rsample::initial_split(daily_fluxes_lae, prop = 0.8, strata = "VPD_F") 
daily_fluxes_lae_train <- rsample::training(split)
daily_fluxes_lae_test <- rsample::testing(split)

split <- rsample::initial_split(daily_fluxes_dav, prop = 0.8, strata = "VPD_F")
daily_fluxes_dav_train <- rsample::training(split)
daily_fluxes_dav_test <- rsample::testing(split)

# Model and pre-processing formulation, use all variables but LW_IN_F
source("../R/Recipe_GPP.R")#get recipie function based on the splitted data.
pp_dav <- recipe_GPP(daily_fluxes_dav_train) 
pp_lae <- recipe_GPP(daily_fluxes_lae_train)


mod_cv_dav <- caret::train(pp_dav, 
                       data = daily_fluxes_dav_train |> drop_na(), 
                       method = "knn",
                       trControl = caret::trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(k = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 60, 100)),
                       metric = "MAE")

mod_cv_lae <- caret::train(pp_lae, 
                       data = daily_fluxes_lae_train |> drop_na(), 
                       method = "knn",
                       trControl = caret::trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(k = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 60, 100)),
                       metric = "MAE")

print(paste("Optimal k of Davos:",mod_cv_dav$bestTune$k))
print(paste("Optimal k of Laegern:",mod_cv_lae$bestTune$k))

```
We can see that the best k was chosen to be 40 for Davos and 30 fr Laegern.

# Within-Site Predictions and Across-Site Predictions

```{r}
source("../R/Evaluate_model_function.R")
#The evaluate function is quite flexible. Also the names of the plots and the return as plots instead of a print can be specified.
plots_1 <- eval_model(mod_cv_dav,daily_fluxes_dav_train,daily_fluxes_dav_test,plot_name1 = "Training set Davos",plot_name2 = "Test set Davos",out="return_plots")
plots_2 <- eval_model(mod_cv_dav,daily_fluxes_dav_test,daily_fluxes_lae_test, plot_name1 = "Test set Davos",plot_name2 = "Test set Laegern",out="return_plots")


plots_3 <- eval_model(mod_cv_lae,daily_fluxes_lae_train,daily_fluxes_lae_test,plot_name1 = "Training set Laegern",plot_name2 = "Test set Laegern",out="return_plots")
plots_4 <- eval_model(mod_cv_lae,daily_fluxes_lae_test,daily_fluxes_dav_test, plot_name1 = "Test set Laegern",plot_name2 = "Test set Davos",out="return_plots")


title_top <- ggdraw() + 
  draw_label(
    "Trained with Davos data",
    fontface = 'bold',
    x = 0,
    hjust = 0)+
  theme(plot.margin = margin(0, 0, 0, 7)) #Title 1

top_row <- cowplot::plot_grid(plots_1[[1]], plots_1[[2]],plots_2[[2]],
                   nrow = 1) #first row of plots

title_bottom <- ggdraw() + 
  draw_label(
    "Trained with Laegern Data",
    fontface = 'bold',
    x = 0,
    hjust = 0)+
  theme(plot.margin = margin(0, 0, 0, 7)) #Title 2

bootom_row <- cowplot::plot_grid(plots_3[[1]], plots_3[[2]],plots_4[[2]],
                   nrow = 1) #second wor of plots.

plot_grid(
  title_top, top_row,title_bottom,bootom_row,
  ncol = 1,
  rel_heights = c(0.1, 1)) #finally we have the combined plot

rm(title_top,title_bottom,top_row,bootom_row,plots_1,plots_2,plots_3,plots_4) #Cleanup after this mess of a plot

```

# Interpreation
The models both perform much better on the test for the data of the site that they were trained for. This is roughly expected since the situation in site may vary a lot in example tree species and climate. This will be discussed later in more dept.


# Single Model

```{r}
set.seed(1982)  # for reproducibility
daily_fluxes <- bind_rows(daily_fluxes_dav,daily_fluxes_lae,.id = "id")


split <- rsample::initial_split(daily_fluxes, prop = 0.7, strata = "VPD_F")

daily_fluxes_train <- rsample::training(split)
daily_fluxes_test <- rsample::testing(split)
source("../R/Recipe_GPP.R")
pp <- recipe_GPP(daily_fluxes_train)
mod_cv <- caret::train(pp, 
                       data = daily_fluxes_train |> drop_na(), 
                       method = "knn",
                       trControl = caret::trainControl(method = "cv", number = 10),
                       tuneGrid = data.frame(k = c(2, 5, 10, 15, 20, 25, 30, 35, 40, 60, 100)),
                       metric = "MAE")

eval_model(mod_cv,daily_fluxes_train,daily_fluxes_test)

daily_fluxes_dav_test <- daily_fluxes_test |>
  filter(id == "1")

#overwriting variables smart -> refactor maybe?
daily_fluxes_lae_test<- daily_fluxes_test |>
  filter(id == "2")

eval_model(mod_cv,daily_fluxes_dav_test,daily_fluxes_lae_test,plot_name1 = "Test Davos",plot_name2 = "Test Laegern",out = "plot_all")



```

The model preforms better for davos than laegern. This might be because davos just simply has more datapoints and therefore is weighted heavier than laegern which introduces a bias towards more accurate predictions for davos.
Furthermore the bias for Laegern is negative and the bias for Davos is positive. 



```{r}


daily_fluxes_dav_test_plot <- daily_fluxes_dav_test |>
  drop_na()
  daily_fluxes_dav_test_plot$fitted <- predict(mod_cv, newdata =  daily_fluxes_dav_test_plot )
  daily_fluxes_dav_test_plot <- daily_fluxes_dav_test_plot |>
  mutate(yearmonth = format(TIMESTAMP, "%m/%Y"),
         residuals = fitted-GPP_NT_VUT_REF)|>
  group_by(yearmonth)|>
  reframe(residuals = mean(residuals),
            year = year(TIMESTAMP))|>
    mutate(month = str_sub(yearmonth,1,2))


ggplot(data = daily_fluxes_dav_test_plot, aes(x = month, y = residuals, group = year, color = factor(year))) +
  geom_line() +
  labs(title = "Davos",color = "Years")+
  theme_classic()

daily_fluxes_dav_test_plot <- daily_fluxes_dav_test |>
  drop_na()
  daily_fluxes_dav_test_plot$fitted <- predict(mod_cv, newdata =  daily_fluxes_dav_test_plot )
  
daily_fluxes_dav_test_plot |>
  mutate(month = factor(month(TIMESTAMP)),
         residuals = fitted-GPP_NT_VUT_REF)|>
  group_by(month)|>
  reframe(residuals = mean(residuals))|>
  ggplot(aes(x = month, y = residuals,group = 1))+
  geom_line()+
  geom_hline(yintercept=0, linetype="dashed", 
               color = "red", size=0.5)+
  ylim(-3,1)+
  labs(title = "Davos")+
  theme_classic()


#--------

daily_fluxes_lae_test_plot <- daily_fluxes_lae_test |>
  drop_na()
  daily_fluxes_lae_test_plot$fitted <- predict(mod_cv, newdata =  daily_fluxes_lae_test_plot )
  daily_fluxes_lae_test_plot <- daily_fluxes_lae_test_plot |>
  mutate(yearmonth = format(TIMESTAMP, "%m/%Y"),
         residuals = fitted-GPP_NT_VUT_REF)|>
  group_by(yearmonth)|>
  reframe(residuals = mean(residuals),
            year = year(TIMESTAMP))|>
    mutate(month = str_sub(yearmonth,1,2))


ggplot(data = daily_fluxes_lae_test_plot, aes(x = month, y = residuals, group = year, color = factor(year))) +
  geom_line() +
  labs(title = "Laegern",color = "Years")+
  theme_classic()

daily_fluxes_lae_test_plot <- daily_fluxes_lae_test |>
  drop_na()
  daily_fluxes_lae_test_plot$fitted <- predict(mod_cv, newdata =  daily_fluxes_lae_test_plot )
  
daily_fluxes_lae_test_plot |>
  mutate(month = factor(month(TIMESTAMP)),
         residuals = fitted-GPP_NT_VUT_REF)|>
  group_by(month)|>
  reframe(residuals = mean(residuals))|>
  ggplot(aes(x = month, y = residuals,group = 1))+
  geom_line()+
  labs(title = "Laegern")+
  geom_hline(yintercept=0, linetype="dashed", 
               color = "red", size=0.5)+
  ylim(-3,1)+
  theme_classic()






```

We can now see the deviations for each year as for each month, and then also the mean of all the years.
Overall, again Laegern shows more deviations on average, which might be due to the higher sample size.
The GPP of Laegern is overestimated a bit in the spring, and underestimated a lot in summer -> makes sense...
The GPP of Davos is quite overestimated in the winter, and underestimated in spring/early summer -> makes sense...
These differences might be induced by different climatic conditions facing these two sites, which intern also lead to another species composition.
As expected Laegern GPP is underestimated in summer and overestimated in winter. This makes sense since Laegern is a mixed forest with a lot of decidous trees. This means that in winter, no potosynthesis even in favorable conditions can occur. But in summer these species might be more productive than the model expects because the unproductivity might have an influence on these measures. Alternativly, deciduous trees might be simply very productive in the summer to compensate for their inactivity in the winter.
For Davos the results were a little bit suprising. There, deviations are much smaller. In the winter, the model slightly overestimates the productivity of the forest. This is suprising since these are mostly evergreen needleleaf which would also be productive during the winter. An explanation could be snow coverage. In case of snow covering trees, the GPP would be approximately 0. This is thesiable since Davos is higher than Laeegern and might experience snow coverage in winter months. Altough if the snow stays on the needles is another question and would need further investigation.